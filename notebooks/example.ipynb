{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the example.ipynb Notebook where it is a simplifed, minimalized notebook to run my programs. If you want more detail and in depth of my programs and my sanity checks and all, please visit the indisvualized notebooks labeled 00-05.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create -n airline-delay-prediction python=3.10 -y || true\n",
    "!conda run -n airline-delay-prediction python -m pip install --upgrade pip\n",
    "!conda run -n airline-delay-prediction python -m pip install -r requirements.txt\n",
    "\n",
    "# (Highly recommended for XGBoost on macOS/Linux)\n",
    "!conda install -n airline-delay-prediction -c conda-forge openjdk=11 -y || true\n",
    "\n",
    "!echo \"âœ“ On the top right of VS Code, make sure to changethe kernel/environment to: 'airline-delay-prediction' \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "def to_repo_root(start=Path.cwd()):\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p/\"src\").exists() and (p/\"requirements.txt\").exists():\n",
    "            os.chdir(p); print(\"Project root:\", p); return\n",
    "    raise SystemExit(\"Could not locate project root (needs ./src and ./requirements.txt)\")\n",
    "to_repo_root()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils_model import (\n",
    "    SCHEMA, BASE_CATEGORICAL, BASE_NUMERIC,\n",
    "    load_model, load_metrics, predict_proba, coerce_schema,\n",
    "    pick_threshold, load_all_metrics_table, score_row, score_dataframe\n",
    ")\n",
    "from pathlib import Path, PurePosixPath\n",
    "import shutil\n",
    "\n",
    "enriched_dir = Path(\"data/processed/flights_enriched\")\n",
    "print(\"Removing:\", enriched_dir.resolve())\n",
    "shutil.rmtree(enriched_dir, ignore_errors=True)\n",
    "(enriched_dir).mkdir(parents=True, exist_ok=True)  # recreate empty dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 01.ipynb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda run -n airline-delay-prediction python src/spark_etl.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather join (Meteostat)\n",
    "\n",
    "!conda run -n airline-delay-prediction python src/merge_weather.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 02.ipynb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will show the plots as well as the report/table I generated after executing code\n",
    "\n",
    "%run src/eda_report.py --show true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will not show plots here but still saves them in reports folder\n",
    "%run src/eda_report.py --show false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 03.ipynb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in the airline-delay-prediction kernel\n",
    "import sys, subprocess, os\n",
    "subprocess.run(\n",
    "    [\"conda\",\"install\",\"-n\",\"airline-delay-prediction\",\"-c\",\"conda-forge\",\"llvm-openmp\",\"-y\"],\n",
    "    check=False\n",
    ")\n",
    "print(\"CONDA_PREFIX:\", os.environ.get(\"CONDA_PREFIX\", sys.prefix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, ctypes, importlib\n",
    "\n",
    "env_prefix = os.environ.get(\"CONDA_PREFIX\", sys.prefix)\n",
    "candidates = glob.glob(os.path.join(env_prefix, \"lib\", \"libomp*.dylib\"))\n",
    "print(\"Found libomp candidates:\", candidates)\n",
    "\n",
    "if not candidates:\n",
    "    raise RuntimeError(\"libomp.dylib not found in the conda env. Make sure llvm-openmp installed in THIS env.\")\n",
    "\n",
    "libomp_path = candidates[0]\n",
    "# Preload OpenMP before importing xgboost\n",
    "ctypes.CDLL(libomp_path)\n",
    "\n",
    "# (Optional) nudge the loader to see the env's lib directory first\n",
    "os.environ[\"DYLD_LIBRARY_PATH\"] = env_prefix + \"/lib:\" + os.environ.get(\"DYLD_LIBRARY_PATH\",\"\")\n",
    "\n",
    "# Now import/test xgboost\n",
    "import xgboost as xgb, numpy as np\n",
    "print(\"XGBoost version:\", xgb.__version__)\n",
    "X = np.random.randn(200, 10); y = (np.random.rand(200) > 0.8).astype(int)\n",
    "d = xgb.DMatrix(X, label=y)\n",
    "xgb.train({'objective':'binary:logistic','tree_method':'hist','verbosity':0}, d, num_boost_round=1)\n",
    "print(\"XGBoost OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training XgBoost on Entire Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/train_xgb.py \\\n",
    "  --in_path data/processed/flights_with_weather.parquet \\\n",
    "  --out_dir models \\\n",
    "  --split time --eval_size 0.20 \\\n",
    "  --early_stopping 50 \\\n",
    "  --n_estimators 1001 \\\n",
    "  --log_period 25 \\\n",
    "  --use_departure_delay true \\\n",
    "  --tag all_features \\\n",
    "  --native true \\\n",
    "  --learning_rate 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training XgBoost with the most valuable feature (to see how much it lowers our predictions for comparsion and funzies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run src/train_xgb.py \\\n",
    "  --in_path data/processed/flights_with_weather.parquet \\\n",
    "  --out_dir models \\\n",
    "  --split time --eval_size 0.20 \\\n",
    "  --early_stopping 50 \\\n",
    "  --n_estimators 1001 \\\n",
    "  --log_period 25 \\\n",
    "  --use_departure_delay false \\\n",
    "  --tag removed_departure_delay_feature \\\n",
    "  --native true \\\n",
    "  --learning_rate 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training CatBoost and Light GBM (bonus so hopefully extra marks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM & CatBoost baselines (time-aware split; same knobs as XGB script)\n",
    "%run src/train_baselines.py \\\n",
    "  --in_path data/processed/flights_with_weather.parquet \\\n",
    "  --out_dir models \\\n",
    "  --split time --eval_size 0.20 \\\n",
    "  --use_departure_delay true \\\n",
    "  --model all \\\n",
    "  --tag all_features \\\n",
    "  --n_estimators 975 \\\n",
    "  --learning_rate 0.1 \\\n",
    "  --early_stopping 100 \\\n",
    "  --log_period 25 \\\n",
    "  --lgbm_max_depth 7 \\\n",
    "  --cat_depth 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 04.ipynb:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning our model with Bayesian Optimization\n",
    "\n",
    "Note: My Macbook is trash so it literally look 20 + hours to run just 10 trials, but you can adjust if you have more compute. My computer was about to explode lolll but yeah the TA said I was fine with this and won't dock points for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian tuning with Optuna (maximize AP over time-aware CV)\n",
    "%run src/tuning_models.py \\\n",
    "  --in_path data/processed/flights_with_weather.parquet \\\n",
    "  --out_dir models \\\n",
    "  --split time --eval_size 0.20 \\\n",
    "  --use_departure_delay true \\\n",
    "  --tag tuned_all_features_bo \\\n",
    "  --cv_folds 5 \\\n",
    "  --bo_trials 10 \\\n",
    "  --bo_startup_trials 10 \\\n",
    "  --bo_timeout 0 \\\n",
    "  --n_rounds 1001 \\\n",
    "  --early_stopping 100 \\\n",
    "  --lr_low 0.03 \\\n",
    "  --lr_high 0.2 \\\n",
    "  --max_depth_low 5 \\\n",
    "  --max_depth_high 9 \\\n",
    "  --min_child_weight_low 1 \\\n",
    "  --min_child_weight_high 8 \\\n",
    "  --subsample_low 0.6 \\\n",
    "  --subsample_high 1.0 \\\n",
    "  --colsample_bytree_low 0.6 \\\n",
    "  --colsample_bytree_high 1.0 \\\n",
    "  --reg_alpha_low 1e-8 \\\n",
    "  --reg_alpha_high 1.0 \\\n",
    "  --reg_lambda_low 1e-2 \\\n",
    "  --reg_lambda_high 10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"models/tuned_all_features_bo_tune_trials.csv\").sort_values(\"cv_ap\", ascending= False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From 05.ipynb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (inside your repo root)\n",
    "!conda activate airline-delay-prediction   # or your env name\n",
    "!conda install -n airline-delay-predictixwon -c conda-forge openjdk=11 -y || true\n",
    "!conda run -n airline-delay-prediction python -m pip install -r requirements.txt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the app\n",
    "!conda run -n airline-delay-prediction streamlit run src/app.py\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
